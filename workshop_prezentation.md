# Postav si vlastnÃ­ AI: open source modely na tvÃ©m stroji

1. Ãšvod do workshopu
	â€¢	KrÃ¡tkÃ© pÅ™edstavenÃ­ lektora a ÃºÄastnÃ­kÅ¯, vysvÄ›tlenÃ­ cÃ­le workshopu.
	â€¢	CÃ­l: pochopit, jak fungujÃ­ open-source LLM a jak je rozjet lokÃ¡lnÄ›.

2. ProÄ mÃ­t vlastnÃ­ AI?
	â€¢	VÃ½hody lokÃ¡lnÃ­ho provozu: nezÃ¡vislost na cloudu, kontrola nad daty, Å¾Ã¡dnÃ© API limity.
	â€¢	ReÃ¡lnÃ© scÃ©nÃ¡Å™e vyuÅ¾itÃ­ (AI asistent, analÃ½za textÅ¯, vÃ½zkum, prototypovÃ¡nÃ­).

3. Typy modelÅ¯: uzavÅ™enÃ© vs. otevÅ™enÃ©
	â€¢	SrovnÃ¡nÃ­ OpenAI, Anthropic, Google vs. open-source projekty (Meta, Mistral, Hugging Face).
	â€¢	VÃ½hody a nevÃ½hody open-source pÅ™Ã­stupu.

4. Jak fungujÃ­ LLM pod kapotou
	â€¢	StruÄnÃ½ pÅ™ehled: tokenizace, trÃ©nink, inferenÄnÃ­ fÃ¡ze.
	â€¢	PÅ™edstava o tom, co znamenÃ¡ 7B, 13B, 70B parametrÅ¯.
	â€¢	Hardware poÅ¾adavky (GPU, RAM, VRAM, CPU fallback).

5. EkosystÃ©m open-source modelÅ¯
	â€¢	PÅ™ehled platforem: Hugging Face, Ollama, LM Studio, vLLM, llama.cpp.
	â€¢	Kde modely hledat, jak je hodnotit (MMLU, Benchmarks, community ratingy).

6. VÃ½bÄ›r modelu pro osobnÃ­ pouÅ¾itÃ­
	â€¢	KritÃ©ria: vÃ½kon vs. velikost, jazykovÃ¡ podpora, Ãºkoly (chat, code, summarizationâ€¦).
	â€¢	PÅ™Ã­klady: Mistral, Llama 3, Phi-3, Gemma, Starling, Zephyr.


ğŸ’» 2. ÄŒÃST â€“ Praxe: SpusÅ¥ si vlastnÃ­ AI lokÃ¡lnÄ›

1. Olama
    â€¢	UkÃ¡zka, jak nainstalovat a spustit Ollamu (Windows/macOS/Linux).
    â€¢	VysvÄ›tlenÃ­, co Ollama dÄ›lÃ¡: lokÃ¡lnÃ­ runtime pro LLM, sprÃ¡va modelÅ¯.

2. Vlastni RAG
    â€¢	UkÃ¡zka, jak nastavit Retrieval-Augmented Generation (RAG) s lokÃ¡lnÃ­m modelem.

4. Vlastni model nebo vlastnÃ­ data
    â€¢	Jak si vytvoÅ™it vlastnÃ­ model (modifikace parametrÅ¯, pÅ™idÃ¡nÃ­ system promptu).
    â€¢	ZmÃ­nka o fine-tuning vs. LoRA vs. RAG.
    â€¢	UkÃ¡zka jednoduchÃ©ho custom modelu v Modelfile.

## 1. Ãšvod do workshopu

VelkÃ© jazykovÃ© modely (LLM = - Large Language Models) jsou hlubokÃ© neuronovÃ© sÃ­tÄ›
(vÄ›tÅ¡inou architektury transformer) trÃ©novanÃ© na obrovskÃ½ch mnoÅ¾stvÃ­ch textovÃ½ch dat,
s cÃ­lem rozumÄ›t a generovat lidskÃ½ text.  ï¿¼
Modely jako GPTâ€‘4, Claude nebo sÃ©rie Llama 3 jsou pÅ™Ã­klady, ale vÄ›tÅ¡ina z nich nenÃ­ â€otevÅ™enÃ¡â€œ.

KlÃ­ÄovÃ© pojmy
	â€¢	Parametr â€“ jeden vÃ¡hovÃ½ koeficient v modelu; model mÅ¯Å¾e mÃ­t miliardy (napÅ™. â€13Bâ€œ znamenÃ¡ ~13 miliard parametrÅ¯).
	â€¢	TransformÃ©r (Transformer) â€“ architektura modelu, kterÃ¡ umoÅ¾Åˆuje tzv. attention mechanismus.
	â€¢	Tokenizace â€“ pÅ™evod vstupnÃ­ho textu na tokeny (menÅ¡Ã­ jednotky, napÅ™. slova/posloupnosti znakÅ¯) pro model.
	â€¢	Inference â€“ fÃ¡ze, kdy model â€bÄ›Å¾Ã­â€œ v reÃ¡lnÃ©m Äase a generuje odpovÄ›di; na rozdÃ­l od trÃ©ninku.
	â€¢	FondovÃ½ model (foundation model) â€“ velkÃ½ univerzÃ¡lnÃ­ model, kterÃ½ lze dÃ¡le upravovat (fine-tuning, LoRA, RAG).

## 2. ProÄ mÃ­t vlastnÃ­ AI?

1. SoukromÃ­ a kontrola dat
    â€¢	Å½Ã¡dnÃ¡ data neopouÅ¡tÃ­ tvÅ¯j poÄÃ­taÄ nebo lokÃ¡lnÃ­ sÃ­Å¥.
    â€¢	IdeÃ¡lnÃ­ pro citlivÃ© projekty (internÃ­ dokumenty, kÃ³d, zÃ¡kaznickÃ¡ data).
    â€¢	VyhneÅ¡ se riziku Ãºniku nebo zneuÅ¾itÃ­ informacÃ­ pÅ™es cloudovÃ© sluÅ¾by.

2. Offline provoz
    â€¢	Funguje i bez internetu.
    â€¢	UÅ¾iteÄnÃ© pro vzdÃ¡lenÃ© lokace, embedded zaÅ™Ã­zenÃ­ nebo experimenty bez pÅ™ipojenÃ­.

3. NÃ¡klady a nezÃ¡vislost
    â€¢	NemusÃ­Å¡ platit za API volÃ¡nÃ­ (OpenAI, Anthropic, apod.).
    â€¢	Nejsi zÃ¡vislÃ½ na zmÄ›nÃ¡ch licencÃ­, limitÅ¯ nebo vÃ½padcÃ­ch poskytovatele.

4. MoÅ¾nost ladÄ›nÃ­ a rozÅ¡Ã­Å™enÃ­
    â€¢	MÅ¯Å¾eÅ¡ upravovat model, pÅ™idÃ¡vat vlastnÃ­ data (fine-tuning, RAG).
    â€¢	Experimenty s architekturami (Llama, Mistral, Gemma, Phi atd.).
    â€¢	PlnÃ¡ kontrola nad prompt engineeringem a pipeline.

## 3. Typy modelÅ¯: uzavÅ™enÃ© vs. otevÅ™enÃ©

### ğŸ§  Co je to open-source LLM

LLM (Large Language Model) je umÄ›lÃ¡ inteligence natrÃ©novanÃ¡ na obrovskÃ©m mnoÅ¾stvÃ­ textÅ¯,
kterÃ¡ dokÃ¡Å¾e rozumÄ›t pÅ™irozenÃ©mu jazyku, odpovÃ­dat, generovat text, pÅ™eklÃ¡dat, psÃ¡t kÃ³d a mnoho dalÅ¡Ã­ho.

ğŸªŸ Open-source LLM = otevÅ™enÃ½ jazykovÃ½ model

ğŸ—ï¸ â€Open-sourceâ€œ znamenÃ¡, Å¾e model je veÅ™ejnÄ› dostupnÃ½ â€“ mÅ¯Å¾eÅ¡ si stÃ¡hnout jeho vÃ¡hy, kÃ³d i architekturu
a pouÅ¾Ã­vat ho bez nutnosti pÅ™ipojenÃ­ ke cloudu.

ğŸ“¦ Co pÅ™esnÄ› bÃ½vÃ¡ otevÅ™enÃ©
    â€¢	ModelovÃ© vÃ¡hy (weights) â€“ samotnÃ© nauÄenÃ© parametry modelu.
    â€¢	Architektura â€“ popis, jak model funguje (poÄet vrstev, attention, embeddingyâ€¦).
    â€¢	KÃ³d pro inference / trÃ©novÃ¡nÃ­ â€“ skripty, kterÃ© umoÅ¾ÅˆujÃ­ model spustit nebo uÄit.
    â€¢	Licence â€“ prÃ¡vnÃ­ rÃ¡mec urÄujÃ­cÃ­, co s modelem smÃ­Å¡ dÄ›lat (napÅ™. MIT, Apache-2.0, Meta License).

### ğŸ”’ UzavÅ™enÃ© (proprietÃ¡rnÃ­) modely

PÅ™Ã­klady: GPT-4 (OpenAI), Claude 3 (Anthropic), Gemini (Google), Copilot (Microsoft)

âœ… VÃ½hody:
    â€¢	NejvyÅ¡Å¡Ã­ kvalita vÃ½stupÅ¯ (velkÃ© mnoÅ¾stvÃ­ trÃ©ninkovÃ½ch dat, optimalizace).
    â€¢	Spolehlivost, bezpeÄnost, stabilita.
    â€¢	PÅ™ipravenÃ© integrace (API, pluginy, Copiloty).
    â€¢	Å½Ã¡dnÃ© starosti s hardwarem â€” bÄ›Å¾Ã­ v cloudu.

âš ï¸ NevÃ½hody:
    â€¢	UzavÅ™enÃ½ kÃ³d a model â€” nevÃ­Å¡, jak byl natrÃ©novÃ¡n.
    â€¢	OmezenÃ­ licencÃ­ a podmÃ­nek (napÅ™. zÃ¡kaz urÄitÃ©ho pouÅ¾itÃ­).
    â€¢	Data putujÃ­ do cloudu (â†’ otÃ¡zky soukromÃ­).
    â€¢	NÃ¡klady podle poÄtu tokenÅ¯ / API volÃ¡nÃ­.
    â€¢	Nelze model pÅ™etrÃ©novat nebo pÅ™izpÅ¯sobit.

### ğŸ§  OtevÅ™enÃ© (open-source) modely

PÅ™Ã­klady: Llama 3 (Meta), Mistral, Gemma (Google), Phi-3 (Microsoft), Falcon, DeepSeek

âœ… VÃ½hody:
    â€¢	PlnÃ¡ kontrola â€” mÅ¯Å¾eÅ¡ model spustit, upravit, kvantizovat, nebo trÃ©novat dÃ¡l.
    â€¢	BÄ›Å¾Ã­ lokÃ¡lnÄ› nebo v privÃ¡tnÃ­m cloudu â†’ Å¾Ã¡dnÃ½ Ãºnik dat.
    â€¢	MÅ¯Å¾eÅ¡ integrovat do vlastnÃ­ch aplikacÃ­ bez omezenÃ­.
    â€¢	Komunita vytvÃ¡Å™Ã­ vylepÅ¡enÃ© varianty (instruct, RAG, agenti).
    â€¢	VÄ›tÅ¡ina licencÃ­ je velmi otevÅ™enÃ¡ (Apache-2.0, MIT, Meta License).

âš ï¸ NevÃ½hody:
    â€¢	VÃ½kon zÃ¡visÃ­ na tvÃ©m hardwaru (RAM, GPU).
    â€¢	Kvalita mÅ¯Å¾e bÃ½t niÅ¾Å¡Ã­ neÅ¾ u top uzavÅ™enÃ½ch modelÅ¯.
    â€¢	VyÅ¾aduje znalosti ohlednÄ› nasazenÃ­ a optimalizace.
    â€¢	MenÅ¡Ã­ modely = menÅ¡Ã­ â€chytrostâ€œ, vÄ›tÅ¡Ã­ = nÃ¡roÄnÃ© na zdroje.

##  4. Jak fungujÃ­ LLM pod kapotou

### ğŸ§© 1ï¸âƒ£ Co LLM vlastnÄ› dÄ›lÃ¡

LLM (Large Language Model) je neuronovÃ¡ sÃ­Å¥, kterÃ¡ se nauÄila pÅ™edpovÃ­dat dalÅ¡Ã­ slovo (token) na zÃ¡kladÄ› pÅ™edchozÃ­ch.

PÅ™Ã­klad:
â€Pes bÄ›Å¾el pÅ™es â€¦â€œ â†’ model se snaÅ¾Ã­ odhadnout, Å¾e dalÅ¡Ã­ token bude â€loukuâ€œ.

ğŸ”¡ 2ï¸âƒ£ Tokenizace â€“ jak se text mÄ›nÃ­ na ÄÃ­sla

Text	        Tokeny	            PoÄet tokenÅ¯
â€Ahoj svÄ›te!â€œ	[Ahoj, svÄ›, te, !]	4
â€Hello world!â€œ	[Hello, world, !]	3

Potom se tokeny pÅ™evedou na ÄÃ­selnÃ© vektory (embeddingy), se kterÃ½mi model poÄÃ­tÃ¡.

ğŸ§© KaÅ¾dÃ½ token je jako souÅ™adnice vÃ½znamu ve vÃ­cerozmÄ›rnÃ©m prostoru.

### ğŸ§± 3ï¸âƒ£ TrÃ©nink â€“ jak se model uÄÃ­ jazyk

Model se uÄÃ­ pÅ™edpovÃ­dat dalÅ¡Ã­ token podle pÅ™edchozÃ­ch.
TrÃ©nuje se na obrovskÃ½ch textech (napÅ™. internet, knihy, kÃ³d, Wikipedie).
Optimalizuje miliony/miliardy parametrÅ¯ (ÄÃ­sel, kterÃ¡ urÄujÃ­, â€co si pamatujeâ€œ).
PouÅ¾Ã­vÃ¡ GPU farmy â€“ trÃ©nink trvÃ¡ tÃ½dny nebo mÄ›sÃ­ce.

ğŸ’¬ VÃ½sledek: model si â€osvojÃ­â€œ statistickÃ© vzorce jazyka â€“ syntax, logiku, fakta i styl.

### âš™ï¸ 4ï¸âƒ£ InferenÄnÃ­ fÃ¡ze â€“ jak model odpovÃ­dÃ¡

To je to, co se dÄ›je pÅ™i kaÅ¾dÃ©m chatu:
â€¢	ZadÃ¡Å¡ prompt â†’ text se tokenizuje.
â€¢	Model spoÄÃ­tÃ¡ pravdÄ›podobnosti pro kaÅ¾dÃ½ moÅ¾nÃ½ dalÅ¡Ã­ token.
â€¢	Vybere nejvhodnÄ›jÅ¡Ã­ (nebo nejpravdÄ›podobnÄ›jÅ¡Ã­).
â€¢	Tento token pÅ™idÃ¡ do vstupu a proces opakuje.

â¡ï¸ Takto vznikÃ¡ odpovÄ›Ä token po tokenu â€“ napÅ™. slovo po slovÄ›.

### ğŸ§® 5ï¸âƒ£ Co znamenÃ¡ 7B, 13B, 70B parametrÅ¯

â€Bâ€œ = miliardy parametrÅ¯ (weights, tj. ÄÃ­sla uloÅ¾enÃ¡ v modelu).
ÄŒÃ­m vÃ­c parametrÅ¯ â†’ tÃ­m vÄ›tÅ¡Ã­ kapacita modelu uÄit se vzorce.

Model	ParametrÅ¯	    Velikost        (FP16)	TypickÃ© vyuÅ¾itÃ­
7B	    7 miliard	    13 GB	        LokÃ¡lnÃ­ bÄ›h, rychlÃ© odpovÄ›di
13B	    13 miliard	    26 GB	        VyvÃ¡Å¾enÃ½ vÃ½kon
70B	    70 miliard	    140 GB	        VÃ½zkum, servery, top kvalita

ğŸ’¡ MenÅ¡Ã­ modely jsou rychlejÅ¡Ã­, ale mÃ©nÄ› pÅ™esnÃ©; vÄ›tÅ¡Ã­ jsou chytÅ™ejÅ¡Ã­, ale nÃ¡roÄnÄ›jÅ¡Ã­.

### ğŸ§° 6ï¸âƒ£ Hardware poÅ¾adavky

ğŸ’» GPU (doporuÄeno)
NejlepÅ¡Ã­ pro inference (paralelnÃ­ vÃ½poÄty).
NapÅ™. NVIDIA RTX 4070/4090 zvlÃ¡dne 7Bâ€“13B modely.
U velkÃ½ch modelÅ¯ (70B+) se pouÅ¾Ã­vajÃ­ vÃ­ce-GPU servery.

ğŸ§  RAM
KvantizovanÃ© modely (napÅ™. GGUF Q4) se vejdou do 8â€“16 GB RAM.
NekvantizovanÃ© modely vyÅ¾adujÃ­ desÃ­tky GB RAM.

ğŸ® VRAM
KaÅ¾dÃ½ GB VRAM â‰ˆ ~1 miliarda parametrÅ¯ (zjednoduÅ¡enÄ›).
7B â†’ 8â€“12 GB VRAM
13B â†’ 16â€“24 GB VRAM
70B â†’ 80â€“140 GB VRAM (server only)

âš™ï¸ CPU fallback
Lze spustit i bez GPU (Ollama, llama.cpp, LM Studio).
VÃ½raznÄ› pomalejÅ¡Ã­, ale pro menÅ¡Ã­ modely pouÅ¾itelnÃ©.
UÅ¾iteÄnÃ© pro testovÃ¡nÃ­ nebo RAG Ãºlohy bez interaktivnÃ­ho chatu.

## 5. EkosystÃ©m open-source modelÅ¯

ğŸŒ 1ï¸âƒ£ Co znamenÃ¡ â€ekosystÃ©mâ€œ open-source modelÅ¯

Open-source AI komunita roste neuvÄ›Å™itelnÄ› rychle â€“ stovky tÃ½mÅ¯ po celÃ©m svÄ›tÄ› vyvÃ­jejÃ­ otevÅ™enÃ© LLM.
To znamenÃ¡:
    â€¢	KaÅ¾dÃ½ si mÅ¯Å¾e model stÃ¡hnout, spustit, upravit nebo natrÃ©novat.
    â€¢	ExistujÃ­ stovky variant (7B, 13B, 70B, kvantizace, fine-tuny).
    â€¢	Vznikl celÃ½ ekosystÃ©m platforem a nÃ¡strojÅ¯, kterÃ© to zpÅ™ehledÅˆujÃ­.

### ğŸ§° 2ï¸âƒ£ PÅ™ehled hlavnÃ­ch platforem a nÃ¡strojÅ¯

ğŸ§¡ Hugging Face
    â€¢	NejvÄ›tÅ¡Ã­ katalog AI modelÅ¯ a datasetÅ¯.
    â€¢	Hostuje tisÃ­ce LLM, nabÃ­zÃ­ testovÃ¡nÃ­ v prohlÃ­Å¾eÄi, API, dokumentaci.
    â€¢	VyhledÃ¡vÃ¡nÃ­, porovnÃ¡vÃ¡nÃ­, sdÃ­lenÃ­ modelÅ¯.

ğŸ¦™ Ollama
    â€¢	NÃ¡stroj pro snadnÃ© spuÅ¡tÄ›nÃ­ modelÅ¯ lokÃ¡lnÄ› (ollama run mistral).
    â€¢	Podporuje Llama, Mistral, Phi, Gemma a dalÅ¡Ã­.
    â€¢	LokÃ¡lnÃ­ inference a integrace do aplikacÃ­.

ğŸ’» LM Studio
    â€¢	GUI aplikace pro Windows/macOS/Linux.
    â€¢	UmoÅ¾Åˆuje stahovat a spouÅ¡tÄ›t modely vizuÃ¡lnÄ›, podobnÄ› jako ChatGPT.
    â€¢	Demo, vÃ½uka, rychlÃ© testy modelÅ¯.

âš¡ vLLM
    â€¢	VÃ½konnÃ½ inference engine vyvinutÃ½ vÃ½zkumnÃ­ky z UC Berkeley.
    â€¢	OptimalizovanÃ½ pro rychlost a Å¡kÃ¡lovÃ¡nÃ­ (API server, GPU cluster).
    â€¢	ProdukÄnÃ­ nasazenÃ­, cloud nebo server.

ğŸ§® llama.cpp
    â€¢	C++ implementace pro bÄ›h modelÅ¯ v kvantizovanÃ© podobÄ› (GGUF).
    â€¢	Velmi efektivnÃ­ â€“ bÄ›Å¾Ã­ i na CPU.
    â€¢	LokÃ¡lnÃ­ testovÃ¡nÃ­, embedded, offline pouÅ¾itÃ­.

### ğŸ“Š 4ï¸âƒ£ Jak modely hodnotit (benchmarks a metriky)

LLM se liÅ¡Ã­ kvalitou, rychlostÃ­ i velikostÃ­.
ExistujÃ­ standardizovanÃ© benchmarks, kterÃ© mÄ›Å™Ã­ rÅ¯znÃ© aspekty schopnostÃ­:

#### Metrika, Co mÄ›Å™Ã­, Typ testÅ¯

MMLU (Massive Multitask Language Understanding)
â€¢	ObecnÃ¡ znalost napÅ™Ã­Ä 57 obory (vÄ›da, historie, prÃ¡vo, IT).
â€¢	VÃ½bÄ›r odpovÄ›di z moÅ¾nostÃ­.

ARC, HellaSwag, TruthfulQA
â€¢	LogickÃ© a faktickÃ© uvaÅ¾ovÃ¡nÃ­.
â€¢	Testy z reÃ¡lnÃ½ch scÃ©nÃ¡Å™Å¯.

GSM8K
â€¢	MatematickÃ© Ãºlohy pro 8. tÅ™Ã­du.
â€¢	VÃ½poÄty a krokovÃ© uvaÅ¾ovÃ¡nÃ­.

HumanEval
â€¢	ProgramovÃ¡nÃ­ â€“ dokÃ¡Å¾e napsat funkci podle zadÃ¡nÃ­?
â€¢	GenerovÃ¡nÃ­ kÃ³du.

## 6. VÃ½bÄ›r modelu pro osobnÃ­ pouÅ¾itÃ­

### ğŸ” KritÃ©ria pro vÃ½bÄ›r modelu

1. VÃ½kon vs. velikost

Velikost modelu (napÅ™. 7B, 13B, 70B parametrÅ¯) silnÄ› ovlivÅˆuje vÃ½poÄetnÃ­ nÃ¡roky i kvalitu vÃ½stupu.
MenÅ¡Ã­ modely â†’ mÃ©nÄ› parametrÅ¯ â†’ rychlejÅ¡Ã­ bÄ›h, menÅ¡Ã­ hardwarovÃ© poÅ¾adavky, ale mohou mÃ­t horÅ¡Ã­ vÃ½kon ve sloÅ¾itÃ½ch ÃºlohÃ¡ch.
VÄ›tÅ¡Ã­ modely â†’ vyÅ¡Å¡Ã­ â€kapacitaâ€œ pro uÄenÃ­ jazykovÃ½ch vzorcÅ¯, kontextu, kÃ³du atp., ale potÅ™ebujÃ­ silnÄ›jÅ¡Ã­ HW (GPU, vÃ­ce VRAM/RAM).

2. JazykovÃ¡ podpora a domÃ©na ÃºkolÅ¯

ZvaÅ¾, zda model podporuje jazyk, ve kterÃ©m budeÅ¡ pracovat (napÅ™. ÄeÅ¡tina, slovenÅ¡tina, angliÄtina)
    â†’ menÅ¡Ã­ modely nebo starÅ¡Ã­ verze mohou mÃ­t horÅ¡Ã­ podporu menÅ¡Ã­ch jazykÅ¯.
Ãškoly: odpovÃ­dÃ¡nÃ­ na dotazy (â€chatâ€œ), generovÃ¡nÃ­ kÃ³du, sumarizace textu, pÅ™eklad, RAG nad vlastnÃ­m datasetem.
    â†’ KaÅ¾dÃ½ model mÃ¡ ve svÃ©m profilu, co zvlÃ¡dÃ¡ dobÅ™e.

3. HardwarovÃ© a provoznÃ­ omezenÃ­

JakÃ½ mÃ¡Å¡ hardware: GPU vÃ½konnÃ©, nebo jen CPU? Kolik VRAM a RAM mÃ¡Å¡? LokÃ¡lnÃ­ inference nebo cloud?
LokÃ¡lnÃ­ pouÅ¾itÃ­: menÅ¡Ã­ modely (napÅ™. ~7B) jsou mnohem praktiÄtÄ›jÅ¡Ã­ pro bÄ›h na bÄ›Å¾nÃ©m PC/GPU Äi dokonce na CPU s kvantizacÃ­.
Pokud nasazujeÅ¡ v produkci nebo mÃ¡Å¡ server, mÅ¯Å¾eÅ¡ zvolit vÄ›tÅ¡Ã­ modely.
Ujisti se, Å¾e model mÃ¡ otevÅ™enou licenci (Apache-2.0, MIT, podobnÄ›) a Å¾e ti dovoluje ho pouÅ¾Ã­vat zpÅ¯sobem, jak potÅ™ebujeÅ¡.
